{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862faea1",
   "metadata": {},
   "source": [
    "## Pyspark Dataframes\n",
    "\n",
    "Jay Urbain, PhD   \n",
    "3/15/2024\n",
    "\n",
    "- PySpark Dataframe \n",
    "- Reading The Dataset\n",
    "- Checking the Datatypes of the Column(Schema)\n",
    "- Selecting Columns And Indexing\n",
    "- Check Describe option similar to Pandas\n",
    "- Adding Columns\n",
    "- Dropping columns\n",
    "- Renaming Columns\n",
    "\n",
    "PySpark documentation:   \n",
    "https://spark.apache.org/docs/latest/api/python/reference/index.html \n",
    "\n",
    "Answer the TODO items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1\n",
    "\n",
    "import os\n",
    "\n",
    "JAVA_HOME = \"/home/jay/anaconda3/envs/pyspark\"\n",
    "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "\n",
    "# option 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/jayurbain/opt/miniconda3/envs/pyspark\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d46445",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551174c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first read the dataset in using pandas as a baseline\n",
    "import pandas https://spark.apache.org/docs/latest/api/python/reference/index.htmlas pd\n",
    "\n",
    "df = pd.read_csv('test1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset, let spark infer the schema\n",
    "df_pyspark=spark.read.option('header','true').csv('test1.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a95903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different syntax\n",
    "\n",
    "df_pyspark=spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type\n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a3c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like pandas head()\n",
    "\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection using pandas\n",
    "\n",
    "# selection\n",
    "\n",
    "df[['Name','Experience']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection using Spark\n",
    "\n",
    "df_pyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865b1ee",
   "metadata": {},
   "source": [
    "Lazy Evaluation means that You can apply as many TRANSFORMATIONs as you want, but Spark will not start the execution of the process until an ACTION is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark[['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8174e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_pyspark[['Name']]\n",
    "df_.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320458c8",
   "metadata": {},
   "source": [
    "Similar to numpy and pandas, pyspark has dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d42722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Columns in data frame\n",
    "df_pyspark=df_pyspark.withColumn('Experience After 2 year',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98641db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop the columns\n",
    "df_pyspark=df_pyspark.drop('Experience After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename the columns\n",
    "df_pyspark.withColumnRenamed('Name','New Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c223e74-5292-4133-a162-d6c560d06d94",
   "metadata": {},
   "source": [
    "#### TODO: Use the agg() function to determine the average salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6fa6f-aaef-44a3-9d44-0ea9b536e92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "777e2943-cbe8-40a8-b64e-f9df5b3feaca",
   "metadata": {},
   "source": [
    "#### TODO: Select the name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e844b296-cb94-4d4c-b9da-4684ff7d7253",
   "metadata": {},
   "source": [
    "#### TODO: Delete the record with name Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5aab2-2ac1-437c-8eef-a47fb284ee4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725bf44d-56a3-487a-a9ef-7213e1885ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pysparek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
